---
title: 分布式锁的设计误区及方案对比
date: 2020-11-15 17:29:00
tags:
---
<!-- toc -->

受不了网上一水的基于Redis、基于ZK实现分布式锁的套路文，不禁想问，这些方案真的是基于分布式的场景来做的吗？下面将结合实际对各种方案进行对比。

# 1 背景梳理

## 1.1 分布式环境的典型特点

- 多点部署
  - 基础环境不可能是单点部署
  - redis通常是哨兵模式部署
  - zk通常3节点以上部署
- 多IDC部署
  - 基础环境很可能也不是单IDC部署
  - 大部分情况是三中心组成一个服务单元
- 网络中断
  - 节点之间网络的连通性并不能得到保证
  - 可能出现抖动、分区等现象
- 网络延迟
  - 节点之间存在网络延迟
  - 在同城多IDC的场景下表现还行，而异地或上云就更大了 
- 故障是必然事件
  - 当基数变大，或时间线拉长，小概率事件都是必然发生的

针对这种场景，CAP与延迟的问题就不得不拿出来在后面进行讨论。

## 1.2 锁服务的典型特点

- 一致性
  - 锁代表着独占资源，一定是全局（或分片，业务也可以通过水平拆分来实现细粒度的锁）唯一的，这对数据一致性提出了最高的要求。也意味着在CAP中先点亮了C。
- 超时机制
  - 锁往往还具有一些特殊属性，如超时释放、可重入等。为了尽可能避免业务异常需要人工恢复，超时释放基本是锁的必备性。

# 2 次优的选择

根据上述条件和要求，下面一项一项分析Redis与ZK的问题。

## 2.1 无法保证一致性的Redis

能检索到的所谓Redis适合作为分布式锁实现的原因之一往往是Redis的提供了数个原子操作的接口，借助原子操作可以实现类似事务的操作，对于实现加锁较为方便。

但到目前Redis6.0为止，Redis主从同步都是异步复制。这意味着某一时刻服务访问主节点成功加锁后，主节点失效；下次该服务另一节点尝试访问从节点升级而成的主节点并没有这条数据，导致重复加锁成功。

无法解决主从数据一致性问题的Redis面对分布式场景的复杂环境，其实并不适合作为锁服务的承载。

## 2.2 节点设计与锁冲突的ZK

ZK相较Redis能够保证数据一致性。但其节点设计并不适合与分布式锁。

其一，ZK的节点类型包括永久节点和临时节点。通常的锁实现往往基于临时节点，而临时节点在session失效后自动被清理，则依赖临时节点作为锁的独占资源很可能在预期外被释放，可能导致重复加锁的出现。

其二，ZK节点的失效时间或者用不失效，或者随Session失效而失效。其没有提供锁超时释放的功能，服务需要借助于其他依赖来实现超时清理的机制，增加复杂性。

考虑以上因素，ZK作为锁的限制太多，也不太适合。

# 3 推荐的选择

## 3.1 etcd

etcd基于raft协议，在实现上不存在一致性问题。

其提供了lease功能，可以对存储的kv设置过期时间，满足锁超时释放的功能。同时lease还存在续约、解约的操作，更加灵活。

提供的revision功能，更加丰富了锁的特性，得以实现公平锁的机制。

## 3.2 Hazelcast

相较上面的3种方案，Hazelcast在国内较冷门。Hazelcast是一个对标Redis的内存存储，基于Java实现。其提供了同步复制的选项，在主从一致性上不存在问题。

Hazelcast同时直接提供了一套锁的API，能够避免手写锁可能带来的错误。其API提供了超时释放等特性

