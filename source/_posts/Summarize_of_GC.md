---
title: GC随笔-读《垃圾回收算法与实现》有感
date: 2020-08-23 23:46:00
tags:
---
<!-- toc -->

--过往通过网络博客补充Java GC（Garbage Collection) 知识，获取到的往往是碎片化的知识，它们充斥着很多近似但不精确的概念，比如Young GC/Full GC/Minor GC/Major GC，比如CMS与Full GC的关系。这些碎片长期没有形成自洽体系，不免希望有个机会能将它们融会贯通，在发现《垃圾回收的算法与实现》一书后，立即着手阅读，达到了部分目标，但此书的实现篇与Java结合不太紧密，甚是遗憾。本文计划对书中概念进行简单总结，理清GC算法理论中的一些概念，同时会简单对几种常见的Java GC实现的特点进行解读。

## 1 什么是GC

### 1.1 GC做了什么

如果要一览GC的全貌，那么对GC的定义我想还是不要略去的比较好。我个人的一句话总结是：**GC为开发者封装手动实现内存分配/回收的细节**。

这里就要提到碎片化知识摄入过多容易产生的第一个误区：GC不是垃圾回收吗，怎么还与内存分配有关系？

GC名字确实叫垃圾回收，但作用域却不仅是垃圾回收。具体细节暂时卖个关子，读完本篇应该就理解了。

### 1.2 GC有什么好处

设想一下没有GC的语言，程序员需要额外做的工作：

- 手动申请内存空间
- 手动释放内存空间
- 手动处理空间不足

当这些事情做多/做少/做错，程序就遇到麻烦了，很多时候甚至会遇到非常难以定位的BUG。

同时，假设部分程序员能够做好这些工作，他们投入在这上面的注意力也是很大一笔成本。就像线程存在自己的上下文、CPU有自己的寄存器，人的脑袋同一时刻能够顾及到的细节也是有限的，当普通人被塞入过多的细节后，很难再进行思考和推演，编程就变成了只有少数人能负担的事情。

### 1.3 GC有必要精通吗

看你个人的目的。比如我，如果只是作为优化编程习惯、解决问题的储备，那么本篇文章可能就是我一段时间的顶点了。

## 2 GC算法的理论基础

在介绍算法之前，按照书中节奏先科普一下概念

### 2.1 概念

- **对象**：对象是GC的基本单位，包含header和field
- **指针**：如果之前没有这个概念，可以简单理解为对象的引用
- **堆**：动态存放对象的内存空间，GC管理的就是堆中已分配的对象
- **活动对象/非活动对象**：能通过根引用（直接引用/间接引用）到的对象是活动对象，也就是会被GC保留的对象；其他是非活动对象，也就是会被GC销毁的对象。
- **根**：根是指向对象的指针的起点
- **GC算法的几个评价标准**：
  - **吞吐量**：单位时间内的处理能力（数据量）
  - **最大暂停时间**：几乎所有的GC算法都会在执行过程中暂停程序执行，这里指的是暂停的最长时间
  - **堆使用效率**：不同的GC算法对堆的使用率不尽相同，主要体现在标志位设计/算法设计等方面
  - **访问的局部性**：具有引用关系的数据尽可能安排在堆中较近的位置，可能提高缓存读取到的概率

### 2.2 标记-清除算法

最简单的算法通常类似于模拟人的行动步骤，标记-清除算法（Mark Sweep GC）即是这样一种算法。如字面意思，该算法由两阶段构成**标记**与**清除**

- **标记阶段**，将所有活动对象做上标记；
- **清除阶段**，将所有没有标记的对象进行回收。

标记阶段更具体的工作内容包括：遍历根引用的对象并进行标记，标记同时对标记对象的引用对象进行标记。这里相当于于深度优先搜索。

清除阶段更具体的工作内容包括：遍历整个堆，将没有标记的对象回收。这里的回收并不指清空目标的内存区域，而是将目标块加入空闲区域的引用队列即可。

当有新对象进行申请时，首先会查找空闲队列中是否存在满足大小的块供分配，否则则是触发一次GC。

- **优点**：实现简单
- **缺点**：
  - 碎片化：空闲链表指向的块并不一定连续，有大有小，再多次GC后，大量碎片即产生
  - 分配速度：查找到符合大小需要的内存可能会遍历整个空闲链表
  - 与写时复制技术不兼容：由于标记跟随对象导致修改标记可能引起内存复制

当然标记-清除原始算法的对于上述的问题，后续也存在非常多的针对性改造，这里简单介绍几种：

- 多个空闲链表：降低分配速度，但没解决碎片化的问题
- BiBOP：减少碎片化，但降低堆使用率
- 位图标记：与写时复制技术兼容，碎片化问题仍然存在

### 2.3 引用计数法

与标记-清除算法相比，引用计数法尝试通过计数器来记录对象被引用的次数，来替代从根开始的对活动对象的遍历搜索。相比之下，引用计数法不存在标记阶段、回收阶段，而是化整为零，分散到了「内存分配」「更新指针」等过程中。例如：

- 申请新对象时，对象的引用计数+1；
- 当有指针指到某对象时，该对象的引用计数+1；
- 当移除指向某对象的指针时，该对象引用计数-1；
- 当某对象引用计数为0时，当场即可回收

上述化整为零的操作贯穿了整个内存管理阶段，也印证了之前所说的**GC的作用域并不只是垃圾回收**。

- **优点**：
  - 可即刻回收垃圾：省略了**标记-清除算法**的标记阶段，每个对象都知道自己的被引用数
  - 最大暂停时间短：将垃圾回收每当发生引用计数归0的状况，该对象即可回收，不需要长时间停顿
- **缺点**：
  - 计数器操作过重：频繁变更引用关系将会导致计数器的开销不少
  - 计数器占用内存空间
  - 循环引用无法回收

当然，针对引用计数原始算法的这些问题，后续也提出了不少的优化方案：

- 延迟引用计数法：减少计数器的频繁操作，但也失去了即刻回收垃圾的优势
- Sticky引用计数法/1位引用计数法：减少计数器占用的空间，也引入了计数器溢出的问题
- 部分标记-清除算法：解决引用计数法无法回收循环引用对象的缺点，但又增加了暂停时间

### 2.4 复制算法

还记得前面的标记-清除算法无法解决的碎片化的问题吗？复制算法在标记活动对象后，将活动对象复制到另一片区域，得以将当前区域全部回收，也就不存在碎片化的对象了。但代价是整个堆被分为两片区域，同一时刻最多利用一片区域，利用率仅50%。

- **优点**：
  - 吞吐量：相比标记-清除算法，复制算法不需要搜索整个堆，能在较短时间内完成GC
  - 高速分配：没有空闲队列这种东西，当完成一次GC后，在空余区域连续分配即可
  - 没有碎片化：空间完全回收
  - 兼容缓存特性：复制算法的实现还有一个特点，将对象及其关联对象在复制后放在相邻位，有利于提升缓存命中
- **缺点**：
  - 堆使用率低：需要两片相同的区域，利用率50%
  - 递归调用：复制算法的实现在复制对象时，需要递归复制子对象，对栈带来很大的额外负担

针对这些问题，也有相当多的优化方案：

- 非递归的复制算法：避免递归，但也失去了关联对象相邻排列的特点
- 非递归近似深度优先的复制：在上面算法的基础上部分保留了关联对象相邻排列的特点
- 多空间复制：提升堆利用率

### 2.5 标记-压缩算法

将标记-清除算法与复制算法有机结合即是标记-压缩算法。以较原始的Lisp2算法为例，在完成标记后，将标记的活动对象直接向前复制到堆的起始位置，连续排列。

- **优点**：堆利用率较高
- **缺点**：压缩（复制）操作较费时间

### 2.6 分代回收算法

到这里算法开始注意到一些工程化实践上的经验，比如堆中大部分对象的生命周期很短，而只有少部分对象会长期存在。基于这个经验（论断），提出将对象分为新生代和和老生代。刚生成的对象为新生代对象，达到一定年龄则成为老生代对象。这里的年龄指存过活的GC次数。针对新生代的垃圾回收称为Minor GC，针对老生代的垃圾回收称为Major GC。

指的注意的是，分代回收算法并不是一个单独的算法，需要结合之前的几种算法来一起工作。

一个较粗略的分代回收实例介绍如下：

- 通常会把整个堆分为**新生代**和**老生代**两个空间，其中新生代又细分为**一个生成空间**和**两个幸存空间**。
- 在新生代首先执行复制算法，生成空间和一个幸存空间中的活动对象复制到另一个幸存空间，生成空间和这个幸存空间同时清空。
- 同时幸存空间中存活过一定年龄的对象也不再在幸存空间之间进行复制，而是晋升到老年代
- 老年代执行的还是标记-压缩算法
- 新生代对象并不只被新生代和根引用，还可能被老生代对象引用。这里引入记录集，记录指向了新生代对象的老生代对象

这里带来的变化包括：

- **优点**：
  - 新生代对象生命周期短的特点，让新生代的复制算法开销很低，大部分对象在下次GC发生时都不再是活动对象，无需被复制
  - 幸存空间存活过一定年龄的对象不在需要经历新生代频繁的复制，而是进入老年代，减少无谓的复制开销
  - 上述两点综合，对吞吐量的改善非常大
  - 老年代对象通常增加缓慢，这里不常发生GC
- 缺点：
  - 并不是很多对象年纪轻轻就死了。对于这类应用，Minor GC开销增大，Major GC次数更加频繁
  - 记录集的操作需要写屏障支持，带来额外负担降低吞吐量

一些对原始分代收集算法的改进：

- 记录集借助操作系统页管理
- 更多代的划分
- 。。。。。。

## 3 GC算法的工程化思考

相信到这里，大家已经对各种GC算法的思路与折衷有个大致的概念。这里主要存在几种主要矛盾：

- Stop-The-World：STW，众所周知的一个概念，表示暂停用户程序的时间
- 算法效率与堆的利用率：各种对象之上增加的标志位、分区设计，都可能在提升算法效率的同时降低堆的利用率
- 吞吐量与最大暂停时间：经过各种优化之后，更单纯的矛盾主要体现在写屏障上

下面分别介绍下这几种矛盾的产生和权衡

### 3.1 针对STW的探索和产出

Java代码开发者最苦大仇深的一点就是程序运行中出现Full GC，往往会导致程序暂停相当长一段时间。等等，Full GC是什么GC？先从Hotspot JVM的实现说起。

Hotspot JVM实现的GC有：

- Serial GC：包括Serial Young GC、Serial Old GC
- Parallel GC：包括Parallel Young GC、非并行的PS MarkSweep GC、并行的Parallel Old GC
- CMS GC：ParNew GC(Young)、CMS GC(Old)、Full GC for CMS
- G1 GC：Young GC、Mixed GC(Young + some old)、Full GC for G1

Full GC针对CMS或G1GC才有，在它们俩的前几种手段都不够用之后，才会触发，是一次全局范围的GC。而程序理想状态下，大部分情况下执行的都是针对新生代的GC。

经过上面的介绍，对Full GC为什么STW这么长时间大家应该也有所领悟了：

- 无论是哪种Full GC实现，都需要对全堆进行扫描
- Full GC实现的算法参照物是标记-压缩算法，也是最费时的一种
- Full GC在JDK10之前的实现都是单线程的（JDK10引入多线程Full GC for G1）

除了避免Full GC之外，还有哪些可以降低STW时间的策略呢：

- 并行收集：单线程跑得慢就多线程
- 并发收集：在不影响用户线程的情况下同时垃圾回收
- 增量式GC：垃圾回收可以分多段，与用户线程交替执行

下面都以Hopspot JVM的几种GC实现为例进行介绍

- 并行收集：通过多线程对单线程的操作进行加速，这里就是Parallel GC与Serial GC的区别
- 并发收集：CMS即是并发的标记-清除收集器，它的几个阶段中，有相当一部分是可以和用户线程同时并发执行的
- 增量式GC：增量式收集正是G1GC的几种特性之一

### 3.2 提升堆利用率

Hotspot JVM中对于堆的划分都是基于分代的，可以调整新生代、老生代、幸存空间的大小。根据前面描述的分代收集算法的特点，通过调整大小来适配我们程序的特点，往往可以表现出更好的GC效率。

当然调整GC策略一定是在程序本身已经进行了充分优化之后的事情。过早、过度优化都是罪。

### 3.3 吞吐量与最大暂停时间

在忽略各种参数调优的情况下（不抬杠），吞吐量可以认为是Parallel GC > CMS GC > G1 GC，而最大暂停时间则是G1 GC < CMS GC < Parallel GC。

这里的差距是由于停顿和并发导致的吗？即是也不是，单纯的停顿和并发，并不应该带来吞吐量的下降，忽略一些细节，那么单位时间内执行的操作数仍然应该是相同的。那么这里问题还是在细节上，也是之前有提到过的**写屏障**。

写屏障在这里并不是指的与volatile相关的内存屏障的概念，而是指的GC算法在内存分配的全周期内均会参与，尤其是新对象分配的时候。例如典型的增量式GC的写屏障，需要将新对象进行标记，并放入标记栈中，已避免标记遗漏。

在有利于程序暂停时间缩短的同时，这些操作也带来了其他不小的开销。

## 4 总结

懒了没对各个算法进行细致讲解，但相信真的阅读到这里，大家应该对各个GC算法的理论有一个大致的框架，知道基础的优劣，同时也明白，GC算法的选择、优化没有银弹，根据实际代码的特性进行权衡，才会达成想要的目标。并且牢记，不要过早优化。

**参考文献**

[1] 《垃圾回收的算法与实现》中村成洋
